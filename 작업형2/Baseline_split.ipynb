{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅분기 작업형2 Baseline\n",
    "- 결과를 보려면 print() 함수 필요\n",
    "- 일반적으로 train, test 두 파일이 제공 $\\rightarrow$ train에서 X, y 분리해야함\n",
    "    - 만약 X_train, X_test, y_train 세 파일이 제공됐다면 위 처럼 X, y를 분리하지 않아도 될 것"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(train.head(), \"\\n\")\n",
    "print(test.shape, \"\\n\")\n",
    "print(test.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) train EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.info(), \"\\n\")\n",
    "print(train.isnull.sum(), \"\\n\") # 결측치 확인\n",
    "print(train.describe(), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) test EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.info(), \"\\n\")\n",
    "print(test.isnull.sum(), \"\\n\") # 결측치 확인\n",
    "print(test.describe(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.describe(include=\"O\"), \"\\n\") # train 범주형 변수 unique 확인\n",
    "print(test.describe(include=\"O\"), \"\\n\") # test 범주형 변수 unique 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train, test에서 범주형 변수의 nuniqie 값 확인하지만.. 아마 시험에서는 값 다르지 않을 것임\n",
    "- 다르게 되면 처리해야할 게 늘어남 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) 결측치 처리 & ID같은 불필요 칼럼 제거 & train에서 X, y 분리\n",
    "- pop 함수는 axis 따로 지정안해도 되는데 drop은 해줘야함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치는 평균보다 이상값에 덜 민감한 중앙값으로 대치\n",
    "# 데이터에 따라 결측치 방법 고려해보기 (0으로 대치, 평균 대치 ...)\n",
    "train[\"칼럼\"] = train[\"칼럼\"].fillna(train[\"칼럼\"].median())\n",
    "test[\"칼럼\"] = test[\"칼럼\"].fillna(test[\"칼럼\"].median())\n",
    "\n",
    "# 결측치 채워졌나 확인\n",
    "print(train.isnull().sum(), \"\\n\")\n",
    "print(test.isnull().sum(), \"\\n\")\n",
    "\n",
    "# 예측에 불필요한 ID 칼럼 제거\n",
    "train = train.drop(\"ID\", axis=1)\n",
    "print(train.head(1), \"\\n\")\n",
    "\n",
    "# test 데이터 ID 분리\n",
    "test_ID = test.pop('ID')\n",
    "print(test.head(1), \"\\n\")\n",
    "\n",
    "y = train.pop(\"타켓 칼럼\") # X, y  분리\n",
    "print(y.head(), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) 스케일링\n",
    "- train에만 fit_transform( ) 해줘야함\n",
    "- test는 transform( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.info(), \"\\n\")\n",
    "\n",
    "con_cols = train.select_dtypes(exclude=\"object\").copy().columns # 수치형 칼럼 선택\n",
    "print(\"수치형 칼럼 : \", con_cols, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train[con_cols] = scaler.fit_transform(train[con_cols])\n",
    "train[con_cols] = scaler.transform(train[con_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3) 인코딩\n",
    "- 어차피 모델은 랜포, lgbm 비교할 거니까 라벨인코딩, 원핫인코딩 두 방법 다 가능할텐데 범주형 변수 내 nunique 값이 많으면 라벨인코딩 하자\n",
    "- train, test nunique 값이 다르다면? \n",
    "    - train, test를 `pd.concat()`으로 합친 후 인코딩해서, 다시 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# Train 데이터와 Test 데이터의 열 순서를 비교하여 동일한 순서로 정렬\n",
    "test = test[train.columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원핫인코딩 후 왜 train, test를 동일한 열 순서로 해야할까? : 올바른 예측, 정확도를 보장하기 위해 !\n",
    "- Train 데이터와 Test 데이터의 열 순서가 일치하지 않으면 모델이 올바르게 예측을 수행할 수 없음\n",
    "- 모델이 학습한 피처 순서와 테스트할 때 입력하는 데이터의 피처 순서가 일치해야함\n",
    "    - 만약 Train 데이터와 Test 데이터의 열 순서가 일치하지 않을 경우, 모델은 학습한 피처의 순서와 다른 피처 순서를 입력으로 받게 되므로 잘못된 결과를 예측할 수 있음\n",
    "- 모델은 Train 데이터를 학습할 때 피처들의 순서에 의존하여 가중치를 조정하고 학습\n",
    "    - 따라서, Train 데이터와 Test 데이터에 동일한 열 순서를 갖도록 정렬해야 모델이 정확한 예측을 수행할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨인코딩\n",
    "cat_cols = train.select_dtypes(include=\"object\").copy().columns # 범주형 칼럼 선택\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "\n",
    "print(train.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 합치기\n",
    "df = pd.concat([train, test])\n",
    "\n",
    "# 인코딩 진행\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = df.select_dtypes(include=\"object\").copy().columns\n",
    "\n",
    "for col in cat_cols :\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "# 인코딩 진행 후 다시 분리\n",
    "train = df[:train.shape[0]].copy()\n",
    "test = df[train.shape[0]:].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 검증 데이터 분리\n",
    "- 분류일 때만 stratify=y \n",
    "    - 데이터를 분할할 때 클래스의 분포를 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y, random_state=1, stratify=y)\n",
    "\n",
    "print(X_train.shape, X_val.shape, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델링\n",
    "- 랜덤포레스트, lgbm 두 개 준비"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) 성능 지표 : 함수 안 매개변수 순서는 실제값, 예측값 순 !\n",
    "- 아래 준비한 성능지표 외에 모르거나 헷갈리는게 나오면 help(), dir() 활용하자\n",
    "- 기본적으로 model.score(x_val, y_val) 하면 분류모델은 정확도를, 회귀모델은 결정계수를 출력한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류 : roc_auc_score, f1_score (다중분류 macro f1), accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀 : RMSE, MSE, MAE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2) 분류"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.predict_proba(x_val)`을 하면 클래스에 따라 나올 확률 값을 행렬로 나타내줌.  \n",
    "즉 칼럼의 순서가 각각의 클래스가 나올 확률 이므로 제출할 형태가 '1일 확률' 이라면 `model.predict_proba(X_val)[:, 1]`을 선택\n",
    "\n",
    "\n",
    "\n",
    "- 예측 확률은 이진분류라고 할 때 0(여자), 1(남자)일 확률 이렇게 두 값이 나옴\n",
    "- 따라서 남자일 확률은 rf.predict_proba(X_val)[:, 1] 이런식으로 지정해줘야함\n",
    "\n",
    "```python\n",
    "rf_pred = rf.predict_proba(X_val) # val 셋에서 남자일 예측 '확률'\n",
    "print(rf_pred)\n",
    "\n",
    "[[0.64 0.36]\n",
    " [0.63 0.37]\n",
    " [0.68 0.32]\n",
    " ...\n",
    " [0.8  0.2 ]\n",
    " [0.55 0.45]\n",
    " [0.69 0.31]]\n",
    " ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_val) # 예측 클래스\n",
    "rf_pred_proba = rf.predict_proba(X_val)[:, 1] # 클래스 1에 대한 예측 확률 \n",
    "\n",
    "# roc_auc_score : 이진분류일 때. 다중분류일 땐  average='macro' 옵션 추가 가능 ... \n",
    "# roc_auc_score만 확률값이랑 비교\n",
    "rf_roc = roc_auc_score(y_val, rf_pred_proba)\n",
    "\n",
    "# macro-f1 : 실제값, 예측값 순\n",
    "rf_f1 =  f1_score(y_val, rf_pred, average = \"macro\") # 다중분류일 때 average = \"macro\" 옵션 사용 !\n",
    "print(rf_f1)\n",
    "\n",
    "# accuracy_score\n",
    "rf_acc = accuracy_score(y_val, rf_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "lgbm_pred = lgbm.predict(X_val)\n",
    "lgbm_pred_proba = lgbm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# roc_auc_score\n",
    "lgbm_roc = roc_auc_score(y_val, lgbm_pred_proba)\n",
    "\n",
    "# f1_score\n",
    "lgbm_f1 = f1_score(y_val, lgbm_pred, average=\"macro\") # macro는 다중분류일 때\n",
    "\n",
    "# accuracy_score\n",
    "lgbm_acc = accuracy_score(y_val, lgbm_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- roc_auc_score만 'proba'랑 비교 !!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3) 회귀"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤포레스트\n",
    "RandomForestRegressor() 매개변수 디폴트 값\n",
    "```\n",
    "   n_estimators=100,\n",
    "    criterion='mse',\n",
    "    max_depth=None,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_val) # 검증용 X_val\n",
    "\n",
    "# rmse\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_val, rf_pred))\n",
    "\n",
    "# r2_score\n",
    "rf_r2 = r2_score(y_val, rf_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lgbm\n",
    "LGBMRegressor() 매개변수 디폴트 값\n",
    "```\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm = LGBMRegressor(random_state=1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "lgbm_pred = lgbm.predict(X_val) # 검증용 X_val\n",
    "\n",
    "# rmse\n",
    "lgbm_rmse = np.sqrt(mean_squared_error(y_val, lgbm.pred))\n",
    "\n",
    "# r2_score\n",
    "lgbm_r2 = r2_score(y_val, lgbm_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 모델 선택해서 test 데이터에 대해 pred / pred_proba 지정해주기 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류\n",
    "pred = rf.predict(test) # 예측 클래스\n",
    "pred_proba = rf.predict_proba(test)[:, 1] # 클래스 1에 대한 예측 확률 \n",
    "\n",
    "pred = lgbm.predict(test)\n",
    "pred_proba = lgbm.predict_proba(test)[:, 1]\n",
    "\n",
    "# 회귀\n",
    "pred = rf.predict(test)\n",
    "pred = lgbm.predict(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 제출 : df & csv 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 -> 데이터 프레임\n",
    "\n",
    "submit = pd.DataFrame({\n",
    "    'ID': test_ID,\n",
    "    'Segmentation': pred\n",
    "})\n",
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv(\"submission.csv\") # 결과 확인\n",
    "print(check.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
