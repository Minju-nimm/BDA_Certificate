{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅분기 작업형2 Baseline\n",
    "- 결과창이 시각적으로 보기 좋지 않으니, print()에 항상 `, \"\\n\"` 넣어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 0. 데이터 로드\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "print(train.shape)\n",
    "print(train.head(), \"\\n\")\n",
    "\n",
    "print(test.shape)\n",
    "print(test.head(), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 1. EDA\n",
    "# 1-1) train EDA\n",
    "print(train.info(), \"\\n\")\n",
    "print(train.isnull().sum(), \"\\n\")\n",
    "print(train.describe(), \"\\n\")\n",
    "\n",
    "# 1-2) test EDA\n",
    "print(test.info(), \"\\n\")\n",
    "print(test.isnull().sum(), \"\\n\")\n",
    "print(test.describe(), \"\\n\")\n",
    "\n",
    "# 범주형 칼럼 고유값 비교\n",
    "print(train.descibe(include=\"O\"), \"\\n\")\n",
    "print(test.describe(\"include=\"O), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. 전처리\n",
    "# 2-1) 결측치 처리, 불필요 칼럼 제거, X와 y 분리\n",
    "\n",
    "# 2-1-1)중앙값으로 결측치 대체\n",
    "train[\"결측 존재 칼럼\"] = train[\"결측 존재 칼럼\"].filna(train[\"결측 존재 칼럼\"].median()) \n",
    "test[\"결측 존재 칼럼\"] = test[\"결측 존재 칼럼\"].fillna(test[\"결측 존재 칼럼\"].median())\n",
    "\n",
    "# 결측치 채워졌나 확인\n",
    "print(train.isnull().sum(), \"\\n\")\n",
    "print(test.isnull().sum(), \"\\n\")\n",
    "\n",
    "# 2-1-2) id 같은 불필요 칼럼 제거\n",
    "train = train.drop(\"id\", axis=1)\n",
    "print(train.head(1), \"\\n\")\n",
    "\n",
    "test_id = test.pop(\"id\") # 결과 제출할 때 test_id는 필요할 수 있음\n",
    "print(test.head(1), \"\\n\")\n",
    "\n",
    "# 2-1-3) X와 y분리\n",
    "y = train.pop(\"예측할 타겟 칼럼\")\n",
    "print(y.head(1), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 2-2) 스케일링 \n",
    "from sklearn.preprocesiing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 연속형 칼럼 선택\n",
    "print(train.info(), \"\\n\")\n",
    "con_cols = train.select_dtypes(exclude=\"object\").copy().columns\n",
    "\n",
    "train[con_cols] = scaler.fit_transform(train[con_cols])\n",
    "test[con_cols] = scaler.transform(test[con_cols])\n",
    "\n",
    "print(train.head(), \"\\n\") # 데이터창이랑 결과창 비교해보기\n",
    "print(test.head(), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 2-3) 인코딩 \n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "test = test[train.columns] # 칼럼 순서 맞춰주기\n",
    "\n",
    "print(train.head(1), \"\\n\")\n",
    "print(test.head(1), \"\\n\")\n",
    "\n",
    "\n",
    "# 3. 검증 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, \n",
    "                                                  y, \n",
    "                                                  random_state=1, \n",
    "                                                  stratify=y) # 분류일 때만 !! \n",
    "\n",
    "print(X_train.shape, X_val.shape)\n",
    "\n",
    "\n",
    "\n",
    "# 4. 모델링 : 랜덤포레스트, lgbm 2개 준비\n",
    "# 4-1) 성능지표\n",
    "# 분류 성능지표\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "# 회귀 성능지표\n",
    "from sklearn.metrics import mean_square_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# 4-2) 분류 모델\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_val) \n",
    "rf_pred_proba = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# roc_auc_score\n",
    "rf_roc = roc_auc_score(y_val, rf_pred_proba)\n",
    "\n",
    "# f1_score\n",
    "rf_f1 = f1_score(y_val, rf_pred, \n",
    "                 average = \"macro\") # 다중분류일 때\n",
    "\n",
    "# accuracy_score\n",
    "rf_acu = accuracy_score(y_val, rf_pred)\n",
    "\n",
    "\n",
    "\n",
    "# lgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import LGBMClassifier\n",
    "lgbm = LGBMClassifier(random_state=1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "lgbm_pred = lgbm.predict(X_val) # 클래스에 대한 예측값\n",
    "lgbm_pred_proba = lgbm.predict_proba(X_val)[:, 1] # 클래스 1에 대한 예측 '확률'\n",
    "\n",
    "# roc_auc_score\n",
    "lgbm_roc = roc_auc_score(y_val, lgbm_pred_proba)\n",
    "\n",
    "# f1_score\n",
    "lgbm_f1 = f1_score(y_val, lgbm_pred,\n",
    "                   average = \"macro\") # 다중분류일 때\n",
    "\n",
    "# accuracy_score\n",
    "lgbm_acu = accuracy_score(y_val, lgbm_pred)\n",
    "\n",
    "\n",
    "\n",
    "# 4-3) 회귀 모델\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_val)\n",
    "\n",
    "# rmse\n",
    "rf_rmse = np.sqrt(mean_square_error(y_val, rf_pred))\n",
    "\n",
    "# r2_score\n",
    "rf_r2 = r2_score(y_val, rf_pred)\n",
    "\n",
    "\n",
    "\n",
    "# lgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "lgbm = LGBMRegressor(random_state=1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_pred = lgbm.predict(X_val)\n",
    "\n",
    "# rmse\n",
    "lgbm_rmse = np.sqrt(mean_square_error(y_val, lgbm_pred))\n",
    "\n",
    "# r2_score\n",
    "lgbm_r2 = r2_score(y_val, lgbm_pred)\n",
    "\n",
    "\n",
    "\n",
    "# 최종 모델 선택하여 pred 지정\n",
    "# 분류일 때 예시\n",
    "# 클래스 예측\n",
    "pred = lgbm.predict(X_val)\n",
    "\n",
    "# 클래스 예측 확률\n",
    "pred = lgbm.predict_proba(X_val)[:, 1] # 정확히 클래스가 어떤 경우의 확률을 말하는지 문제 꼼꼼히 읽을 것 \n",
    "\n",
    "# 회귀일 때 예시\n",
    "pred = lgbm.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "# 5. 제출 : df, csv\n",
    "submit = pd.DataFrame({\"id\" : test_id, \"pred / 제출 칼럼명 자세히 보기\" : pred})\n",
    "submit.to_csv(\"수험번호.csv\", index=False)\n",
    "\n",
    "check = pd.read_csv(\"수험번호.csv\") # 제출 잘 됐는지 확인"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
