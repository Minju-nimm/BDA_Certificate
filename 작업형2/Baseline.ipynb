{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅분기 작업형2 Baseline\n",
    "- 결과창이 시각적으로 보기 좋지 않으니 print()에 `, \"\\n\"` 넣어주기\n",
    "- train, test 데이터에서 범주형 변수의 nunique 값이 다를 때?\n",
    "    - 두 데이터를 먼저 합친 후 인코딩 진행, 그리고 다시 데이터 분리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 디폴트 값\n",
    "    - 랜덤포레스트 : max_depth= None, n_estimators = 100\n",
    "    - lgbm : max_depth=-1, n_estimators = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 0. 데이터 로드\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "print(\"train=======================\")\n",
    "print(train.shape)\n",
    "print(train.head(), \"\\n\")\n",
    "\n",
    "print(\"test=======================\")\n",
    "print(test.shape)\n",
    "print(test.head(), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 1. EDA\n",
    "# 1-1) train EDA\n",
    "print(train.info(), \"\\n\")\n",
    "print(train.isnull().sum(), \"\\n\")\n",
    "print(train.describe(), \"\\n\")\n",
    "\n",
    "# 1-2) test EDA\n",
    "print(test.info(), \"\\n\")\n",
    "print(test.isnull().sum(), \"\\n\")\n",
    "print(test.describe(), \"\\n\")\n",
    "\n",
    "# 범주형 칼럼 고유값 비교\n",
    "print(train.describe(include=\"O\"), \"\\n\")\n",
    "print(test.describe(include=\"O\"), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. 전처리\n",
    "# 2-1) 결측치 처리, 불필요 칼럼 제거, X와 y 분리\n",
    "\n",
    "# 2-1-1)중앙값으로 결측치 대체\n",
    "train[\"결측 존재 칼럼\"] = train[\"결측 존재 칼럼\"].fillna(train[\"결측 존재 칼럼\"].median()) \n",
    "test[\"결측 존재 칼럼\"] = test[\"결측 존재 칼럼\"].fillna(test[\"결측 존재 칼럼\"].median())\n",
    "\n",
    "# 결측치 채워졌나 확인\n",
    "print(train.isnull().sum(), \"\\n\")\n",
    "print(test.isnull().sum(), \"\\n\")\n",
    "\n",
    "# 2-1-2) id 같은 불필요 칼럼 제거\n",
    "train = train.drop(\"id\", axis=1)\n",
    "\n",
    "test_id = test.pop(\"id\") # 결과 제출할 때 test_id 필요할 수 있음\n",
    "\n",
    "# 2-1-3) X와 y분리\n",
    "y = train.pop(\"예측할 타겟 칼럼\")\n",
    "\n",
    "print(\"train=======================\")\n",
    "print(train.head(3), \"\\n\")\n",
    "print(\"test=======================\")\n",
    "print(test.head(3), \"\\n\")\n",
    "print(y.head(1), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 2-2) 스케일링 \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 연속형 칼럼 선택\n",
    "print(train.info(), \"\\n\")\n",
    "con_cols = train.select_dtypes(exclude=\"object\").copy().columns\n",
    "print(\"연속형 칼럼 : \", con_cols)\n",
    "\n",
    "train[con_cols] = scaler.fit_transform(train[con_cols])\n",
    "test[con_cols] = scaler.transform(test[con_cols])\n",
    "\n",
    "\n",
    "\n",
    "# 2-3) 인코딩 \n",
    "# 원핫인코딩 : train & test nunique 동일하고 \n",
    "# nunique 개수가 많지 않다고 판단 될 떄\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "test = test[train.columns] # 칼럼 순서 맞춰주기\n",
    "\n",
    "\n",
    "\n",
    "# 라벨인코딩 : train, test nunique 다를 때 & 범주형 데이터 nunique 많을 때\n",
    "# 먼저 train, test 합쳐주기\n",
    "df = pd.concat([train, test])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 범주형 칼럼 선택\n",
    "cat_cols = train.select_dtypes(include=\"object\").copy().columns\n",
    "print(\"범주형 칼럼 : \", cat_cols )\n",
    "\n",
    "for col in cat_cols : \n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transfrom(df[col])\n",
    "\n",
    "# train, test 분리\n",
    "train = df[: train.shape[0]].copy()\n",
    "test = df[train.shape[0]:].copy()\n",
    "\n",
    "\n",
    "\n",
    "# 스케일링, 인코딩 잘 적용됐나 확인\n",
    "print(\"train=======================\")\n",
    "print(train.head(3), \"\\n\")\n",
    "print(\"test=======================\")\n",
    "print(test.head(3), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 3. 검증 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, \n",
    "                                                  y, \n",
    "                                                  random_state=1, \n",
    "                                                  stratify=y) # 분류일 때만 !! \n",
    "\n",
    "print(X_train.shape, X_val.shape, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# 4. 모델링 : 랜덤포레스트, lgbm 2개 준비\n",
    "# 4-1) 성능지표\n",
    "# 분류 성능지표\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 회귀 성능지표\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# 4-2) 분류 모델\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_val) \n",
    "rf_pred_proba = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# roc_auc_score\n",
    "rf_roc = roc_auc_score(y_val, rf_pred_proba)\n",
    "\n",
    "# f1_score\n",
    "rf_f1 = f1_score(y_val, rf_pred, \n",
    "                 average = \"macro\") # 다중분류일 때\n",
    "\n",
    "# accuracy_score\n",
    "rf_acu = accuracy_score(y_val, rf_pred)\n",
    "\n",
    "\n",
    "\n",
    "# lgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(random_state=1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "lgbm_pred = lgbm.predict(X_val) # 클래스에 대한 예측값\n",
    "lgbm_pred_proba = lgbm.predict_proba(X_val)[:, 1] # 클래스 1에 대한 예측 '확률'\n",
    "\n",
    "# roc_auc_score\n",
    "lgbm_roc = roc_auc_score(y_val, lgbm_pred_proba)\n",
    "\n",
    "# f1_score\n",
    "lgbm_f1 = f1_score(y_val, lgbm_pred,\n",
    "                   average = \"macro\") # 다중분류일 때\n",
    "\n",
    "# accuracy_score\n",
    "lgbm_acu = accuracy_score(y_val, lgbm_pred)\n",
    "\n",
    "\n",
    "\n",
    "# 4-3) 회귀 모델\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_val)\n",
    "\n",
    "# rmse\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_val, rf_pred))\n",
    "\n",
    "# r2_score\n",
    "rf_r2 = r2_score(y_val, rf_pred)\n",
    "\n",
    "\n",
    "\n",
    "# lgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "lgbm = LGBMRegressor(random_state=1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_pred = lgbm.predict(X_val)\n",
    "\n",
    "# rmse\n",
    "lgbm_rmse = np.sqrt(mean_squared_error(y_val, lgbm_pred))\n",
    "\n",
    "# r2_score\n",
    "lgbm_r2 = r2_score(y_val, lgbm_pred)\n",
    "\n",
    "\n",
    "\n",
    "# 최종 모델 선택하여 test 데이터에 대해 pred 지정\n",
    "# 분류일 때 예시\n",
    "# 클래스 예측 & 회귀도 동일\n",
    "pred = lgbm.predict(test)\n",
    "\n",
    "# 클래스 예측 확률\n",
    "# 정확히 클래스가 어떤 경우의 확률을 말하는지 문제 꼼꼼히 읽을 것 \n",
    "pred = lgbm.predict_proba(test)[:, 1] \n",
    "\n",
    "\n",
    "\n",
    "# 5. 제출 : df, csv\n",
    "submit = pd.DataFrame({\"id\" : test_id, \"pred / 제출 칼럼명 자세히 보기\" : pred})\n",
    "submit.to_csv(\"수험번호.csv\", index=False)\n",
    "\n",
    "check = pd.read_csv(\"수험번호.csv\") # 제출 잘 됐는지 확인\n",
    "print(check.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 튜닝 : 그리드 서치\n",
    "### 분류\n",
    "| 성능 지표  | scoring 옵션   |\n",
    "|---|---|\n",
    "| roc_auc_score  | scoring = \"roc_auc\"   |\n",
    "| f1_score  |  scoring = \"f1\" |\n",
    "| macro f1_score  |        scoring = scorer              |\n",
    "\n",
    "```python \n",
    "# 다중분류 일 때 scorer 생성 후, scoring = scorer 할당\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 하이퍼 파라미터 튜닝\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=2023)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier\n",
    "\n",
    "models = [rf, lgbm]\n",
    "\n",
    "params= {\"max_depth\" : [1,2,3], \"n_estimators\" : [100, 200, 300]}\n",
    "\n",
    "# # 다중분류, macro f1 일 때\n",
    "# socrer = make_scorer(f1_score, average=\"macro\")\n",
    "\n",
    "# scoring=\"f1\" / scoring = scorer\n",
    "\n",
    "for model in models :\n",
    "    gs = GridSearchCV(model, cv=5, param_grid = params, scoring=\"roc_auc\", n_jobs=4) \n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"==\"10)\n",
    "    print(f\"model : {model}\")\n",
    "    print(f\"최적 파라미터 : {gs.best_params_}\")\n",
    "    print(f\"best score : {gs.best_score_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀\n",
    "| 성능 지표  | scoring 옵션   |\n",
    "|---|---|\n",
    "| r2_score  | scoring = \"r2\"   |\n",
    "| RMSE  |  scoring=\"neg_root_mean_squared_error\" |\n",
    "| mean_absolute_error |       scoring=\"neg_mean_absolute_error\"        |\n",
    "\n",
    "- 회귀의 지표 RMSE, MAE는 작을수록 성능이 좋기 때문에, -gs.best_score_ 이렇게 점수에 마이너스 붙여줘야 함 !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 하이퍼 파라미터 튜닝\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=2023)\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "lgbm = LGBMRegressor(random_state=2023)\n",
    "\n",
    "models = [rf, lgbm]\n",
    "params = {\"max_depth\" : [1, 2, 3], \"n_estimators\" : [100, 200, 300]}\n",
    "\n",
    "for model in models :\n",
    "    gs = GridSearchCV(model, cv=5, param_grid=params, \n",
    "                      scoring=\"neg_root_mean_squared_error\", n_jobs=4)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"==\"*10)\n",
    "    print(f\"model : {model}\")\n",
    "    print(f\"최적 파라미터 : {gs.best_params_}\")\n",
    "    print(f\"최적 점수 : {-gs.best_score_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증은 모델의 성능을 신뢰할 수 있는 추정치를 제공하기 위해 사용되지만, 실제 검증 데이터에서의 성능은 교차 검증의 best_score와 차이가 있을 수 있다. 왜 그럴까?\n",
    "\n",
    "$\\rightarrow$ 최적화된 파라미터가 학습 데이터에 과적합(overfitting)되어 일반화 능력이 저하될 수 있기 떄문 !\n",
    "- 그리드 서치는 학습 데이터를 기반으로 모델의 파라미터 조합을 탐색하여 최적의 조합을 탐색\n",
    "- 그러나 학습 데이터에 대해서는 최적의 조합일지라도, 검증용 데이터나 새로운 데이터에 대해서는 일반화 성능이 좋지 않을 수 있음\n",
    "- 모델이 학습 데이터에 지나치게 맞추어져서 새로운 패턴이나 변동성을 제대로 반영하지 못하는 경우가 있기 때문\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
